{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ac9755",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_27576/3479285374.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# Create DataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# Generate descriptive statistics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    612\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m             \u001b[1;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 614\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    615\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    462\u001b[0m         \u001b[1;31m# TODO: can we get rid of the dt64tz special case above?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 464\u001b[1;33m     return arrays_to_mgr(\n\u001b[0m\u001b[0;32m    465\u001b[0m         \u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m     )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    633\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"All arrays must be of the same length\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create the dataset as a dictionary of lists (replace with your data)\n",
    "data = {\n",
    "    'J1': [4, 2, 2, 4, 2, 4, 3, 1, 2, 4, 4, 3, 2, 2, 4, 2, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1, 4, 1, 2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 3, 2, 1, 5, 2, 1, 2, 2, 1, 4, 2, 1, 1, 4, 2, 2, 4, 1, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1, 4, 2, 1, 2, 1, 1, 2, 2, 1, 2, 2, 2, 2, 4, 2, 1, 1, 4, 2, 4, 2, 2, 1, 2, 2, 2],\n",
    "    'J2': [2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 1, 3, 2, 4, 2, 4, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 3, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 4, 2, 2, 4, 3, 2, 2, 4, 2, 1, 2, 4, 2, 4, 1, 1, 1, 2, 1, 1, 5, 5, 1, 2, 2, 1, 2, 1, 4, 2, 2, 4, 1, 1, 2, 2, 1, 2, 2, 4, 2, 4],\n",
    "    'J3': [1, 2, 3, 3, 3, 2, 2, 4, 3, 4, 3, 2, 3, 2, 1, 4, 3, 2, 2, 1, 4, 2, 3, 3, 4, 4, 3, 3, 4, 3, 5, 5, 2, 2, 4, 3, 2, 3, 2, 4, 2, 3, 4, 4, 4, 4, 4, 2, 4, 4, 3, 2, 3, 2, 4, 4, 4, 2, 4, 2, 3, 2, 4, 4, 3, 2, 3, 4, 4, 5, 5, 4, 5, 3, 2, 4, 3, 3, 3, 3, 3, 4, 2, 5, 4, 3, 4, 4, 4, 4, 2, 2, 4, 2, 1, 4, 4, 4, 4, 4],\n",
    "    'J4': [1, 1, 2, 2, 3, 2, 2, 2, 3, 4, 2, 2, 3, 2, 1, 4, 3, 5, 5, 1, 2, 3, 2, 3, 4, 2, 3, 3, 2, 3, 5, 5, 4, 2, 4, 3, 3, 3, 4, 2, 1, 3, 5, 4, 3, 5, 4, 2, 2, 4, 4, 2, 4, 4, 4, 2, 4, 2, 2, 4, 2, 2, 3, 4, 4, 2, 2, 2, 2, 4, 4, 4, 2, 1, 4, 1, 1, 4, 5, 2, 2, 4, 2, 5, 1, 5, 4, 5, 5, 5, 2, 3, 5, 2, 1, 2, 5, 2, 3, 2],\n",
    "    'J5': [1, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 1, 2, 2, 4, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 3, 4, 3, 1, 2, 1, 2, 1, 2, 2, 4, 2, 2, 3, 2, 1, 2, 2, 1, 2, 2, 4, 2, 2, 4, 2, 1, 2, 1, 2, 2, 2, 3, 2, 4, 3, 1, 2, 2, 2, 3, 3, 4, 2, 1, 4, 2, 1, 2, 4, 4, 1, 4, 4, 4, 4, 2, 4, 3, 2, 2, 1, 2, 1, 4, 3, 1, 3, 3, 2],\n",
    "    'J6': [2, 4, 5, 4, 1, 3, 4, 4, 5, None, 2, 4, 5, 2, 4, 3, 4, 2, 4, 4, 4, 4, 4, 4, 5, 5, 4, 5, 3, 4, 3, 1, 4, 4, 4, 5, 5, 5, 4, 4, 4, 4, 5, 4, 4, 4, 4, 2, 2, 4, 4, 3, 4, 2, 2, 4, 5, 5, 2, 5, 5, 2, 4, 5, 4, 4, 5, 5, 3, 4, 4, 4, 5, 4, 5, 5, 5, 5, 5, 4, 4, 5, 5, 5, 5, 4, 2, 4, 4, 4, 4, 2, 3, 5, 3, 4, 2, 5, 4, 3, 3],\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Generate descriptive statistics\n",
    "statistics = df.describe()\n",
    "\n",
    "print(statistics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce98c7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               J1          J2         J3          J4          J5          J6\n",
      "count  100.000000  100.000000  100.00000  100.000000  100.000000  100.000000\n",
      "mean     2.010000    2.130000    3.17000    2.970000    2.270000    3.870000\n",
      "std      1.010001    0.970837    1.00559    1.250899    0.951925    1.041124\n",
      "min      1.000000    1.000000    1.00000    1.000000    1.000000    1.000000\n",
      "25%      1.000000    2.000000    2.00000    2.000000    2.000000    3.750000\n",
      "50%      2.000000    2.000000    3.00000    3.000000    2.000000    4.000000\n",
      "75%      2.000000    2.000000    4.00000    4.000000    3.000000    5.000000\n",
      "max      5.000000    5.000000    5.00000    5.000000    4.000000    5.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create the dataset as a dictionary of lists (replace with your data)\n",
    "data = {\n",
    "    'J1': [4, 2, 2, 4, 2, 4, 3, 1, 2, 4, 4, 3, 2, 2, 4, 2, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1, 4, 1, 2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 3, 2, 1, 5, 2, 1, 2, 2, 1, 4, 2, 1, 1, 4, 2, 2, 4, 1, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1, 4, 2, 1, 2, 1, 1, 2, 2, 1, 2, 2, 2, 2, 4, 2, 1, 1, 4, 2, 4, 2, 2, 1, 2, 2, 2],\n",
    "    'J2': [2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 1, 3, 2, 4, 2, 4, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 3, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 4, 2, 2, 4, 3, 2, 2, 4, 2, 1, 2, 4, 2, 4, 1, 1, 1, 2, 1, 1, 5, 5, 1, 2, 2, 1, 2, 1, 4, 2, 2, 4, 1, 1, 2, 2, 1, 2, 2, 4, 2, 4],\n",
    "    'J3': [1, 2, 3, 3, 3, 2, 2, 4, 3, 4, 3, 2, 3, 2, 1, 4, 3, 2, 2, 1, 4, 2, 3, 3, 4, 4, 3, 3, 4, 3, 5, 5, 2, 2, 4, 3, 2, 3, 2, 4, 2, 3, 4, 4, 4, 4, 4, 2, 4, 4, 3, 2, 3, 2, 4, 4, 4, 2, 4, 2, 3, 2, 4, 4, 3, 2, 3, 4, 4, 5, 5, 4, 5, 3, 2, 4, 3, 3, 3, 3, 3, 4, 2, 5, 4, 3, 4, 4, 4, 4, 2, 2, 4, 2, 1, 4, 4, 4, 4, 4],\n",
    "    'J4': [1, 1, 2, 2, 3, 2, 2, 2, 3, 4, 2, 2, 3, 2, 1, 4, 3, 5, 5, 1, 2, 3, 2, 3, 4, 2, 3, 3, 2, 3, 5, 5, 4, 2, 4, 3, 3, 3, 4, 2, 1, 3, 5, 4, 3, 5, 4, 2, 2, 4, 4, 2, 4, 4, 4, 2, 4, 2, 2, 4, 2, 2, 3, 4, 4, 2, 2, 2, 2, 4, 4, 4, 2, 1, 4, 1, 1, 4, 5, 2, 2, 4, 2, 5, 1, 5, 4, 5, 5, 5, 2, 3, 5, 2, 1, 2, 5, 2, 3, 2],\n",
    "    'J5': [1, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 1, 2, 2, 4, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 3, 4, 3, 1, 2, 1, 2, 1, 2, 2, 4, 2, 2, 3, 2, 1, 2, 2, 1, 2, 2, 4, 2, 2, 4, 2, 1, 2, 1, 2, 2, 2, 3, 2, 4, 3, 1, 2, 2, 2, 3, 3, 4, 2, 1, 4, 2, 1, 2, 4, 4, 1, 4, 4, 4, 4, 2, 4, 3, 2, 2, 1, 2, 1, 4, 3, 1, 3, 3, 2],\n",
    "    'J6': [2, 4, 5, 4, 1, 3, 4, 4, 5, None, 2, 4, 5, 2, 4, 3, 4, 2, 4, 4, 4, 4, 4, 4, 5, 5, 4, 5, 3, 4, 3, 1, 4, 4, 4, 5, 5, 5, 4, 4, 4, 4, 5, 4, 4, 4, 4, 2, 2, 4, 4, 3, 4, 2, 2, 4, 5, 5, 2, 5, 5, 2, 4, 5, 4, 4, 5, 5, 3, 4, 4, 4, 5, 4, 5, 5, 5, 5, 5, 4, 4, 5, 5, 5, 5, 4, 2, 4, 4, 4, 4, 2, 3, 5, 3, 4, 2, 5, 4, 3, 3],\n",
    "}\n",
    "\n",
    "# Find the maximum length of arrays\n",
    "max_length = max(len(lst) for lst in data.values())\n",
    "\n",
    "# Ensure all arrays are of the same length by padding with None\n",
    "for key, value in data.items():\n",
    "    if len(value) < max_length:\n",
    "        data[key] = value + [None] * (max_length - len(value))\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Generate descriptive statistics\n",
    "statistics = df.describe()\n",
    "\n",
    "# Output the statistics\n",
    "print(statistics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05edf3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Mean  Median  Mode  Standard Deviation  Variance  Range  Skewness  \\\n",
      "J1  2.01     2.0   2.0            1.010001  1.020101    4.0  1.060127   \n",
      "J2  2.13     2.0   2.0            0.970837  0.942525    4.0  1.288502   \n",
      "J3  3.17     3.0   4.0            1.005590  1.011212    4.0 -0.228545   \n",
      "J4  2.97     3.0   2.0            1.250899  1.564747    4.0  0.184015   \n",
      "J5  2.27     2.0   2.0            0.951925  0.906162    3.0  0.649625   \n",
      "J6  3.87     4.0   4.0            1.041124  1.083939    4.0 -0.885292   \n",
      "\n",
      "    Kurtosis    Q1   Q3  Interquartile Range (IQR)  Min  Max  Count  Missing  \n",
      "J1  0.379430  1.00  2.0                       1.00  1.0  5.0    100        1  \n",
      "J2  1.425520  2.00  2.0                       0.00  1.0  5.0    100        1  \n",
      "J3 -0.774748  2.00  4.0                       2.00  1.0  5.0    100        1  \n",
      "J4 -1.136590  2.00  4.0                       2.00  1.0  5.0    100        1  \n",
      "J5 -0.446239  2.00  3.0                       1.00  1.0  4.0    100        1  \n",
      "J6  0.082800  3.75  5.0                       1.25  1.0  5.0    100        1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create the dataset (replace with your data)\n",
    "data = {\n",
    "    'J1': [4, 2, 2, 4, 2, 4, 3, 1, 2, 4, 4, 3, 2, 2, 4, 2, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1, 4, 1, 2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 3, 2, 1, 5, 2, 1, 2, 2, 1, 4, 2, 1, 1, 4, 2, 2, 4, 1, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1, 4, 2, 1, 2, 1, 1, 2, 2, 1, 2, 2, 2, 2, 4, 2, 1, 1, 4, 2, 4, 2, 2, 1, 2, 2, 2],\n",
    "    'J2': [2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 1, 3, 2, 4, 2, 4, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 3, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 4, 2, 2, 4, 3, 2, 2, 4, 2, 1, 2, 4, 2, 4, 1, 1, 1, 2, 1, 1, 5, 5, 1, 2, 2, 1, 2, 1, 4, 2, 2, 4, 1, 1, 2, 2, 1, 2, 2, 4, 2, 4],\n",
    "    'J3': [1, 2, 3, 3, 3, 2, 2, 4, 3, 4, 3, 2, 3, 2, 1, 4, 3, 2, 2, 1, 4, 2, 3, 3, 4, 4, 3, 3, 4, 3, 5, 5, 2, 2, 4, 3, 2, 3, 2, 4, 2, 3, 4, 4, 4, 4, 4, 2, 4, 4, 3, 2, 3, 2, 4, 4, 4, 2, 4, 2, 3, 2, 4, 4, 3, 2, 3, 4, 4, 5, 5, 4, 5, 3, 2, 4, 3, 3, 3, 3, 3, 4, 2, 5, 4, 3, 4, 4, 4, 4, 2, 2, 4, 2, 1, 4, 4, 4, 4, 4],\n",
    "    'J4': [1, 1, 2, 2, 3, 2, 2, 2, 3, 4, 2, 2, 3, 2, 1, 4, 3, 5, 5, 1, 2, 3, 2, 3, 4, 2, 3, 3, 2, 3, 5, 5, 4, 2, 4, 3, 3, 3, 4, 2, 1, 3, 5, 4, 3, 5, 4, 2, 2, 4, 4, 2, 4, 4, 4, 2, 4, 2, 2, 4, 2, 2, 3, 4, 4, 2, 2, 2, 2, 4, 4, 4, 2, 1, 4, 1, 1, 4, 5, 2, 2, 4, 2, 5, 1, 5, 4, 5, 5, 5, 2, 3, 5, 2, 1, 2, 5, 2, 3, 2],\n",
    "    'J5': [1, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 1, 2, 2, 4, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 3, 4, 3, 1, 2, 1, 2, 1, 2, 2, 4, 2, 2, 3, 2, 1, 2, 2, 1, 2, 2, 4, 2, 2, 4, 2, 1, 2, 1, 2, 2, 2, 3, 2, 4, 3, 1, 2, 2, 2, 3, 3, 4, 2, 1, 4, 2, 1, 2, 4, 4, 1, 4, 4, 4, 4, 2, 4, 3, 2, 2, 1, 2, 1, 4, 3, 1, 3, 3, 2],\n",
    "    'J6': [2, 4, 5, 4, 1, 3, 4, 4, 5, None, 2, 4, 5, 2, 4, 3, 4, 2, 4, 4, 4, 4, 4, 4, 5, 5, 4, 5, 3, 4, 3, 1, 4, 4, 4, 5, 5, 5, 4, 4, 4, 4, 5, 4, 4, 4, 4, 2, 2, 4, 4, 3, 4, 2, 2, 4, 5, 5, 2, 5, 5, 2, 4, 5, 4, 4, 5, 5, 3, 4, 4, 4, 5, 4, 5, 5, 5, 5, 5, 4, 4, 5, 5, 5, 5, 4, 2, 4, 4, 4, 4, 2, 3, 5, 3, 4, 2, 5, 4, 3, 3],\n",
    "}\n",
    "\n",
    "# Find the maximum length of arrays\n",
    "max_length = max(len(lst) for lst in data.values())\n",
    "\n",
    "# Ensure all arrays are of the same length by padding with None\n",
    "for key, value in data.items():\n",
    "    if len(value) < max_length:\n",
    "        value.extend([None] * (max_length - len(value)))\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Function to calculate range\n",
    "def data_range(x):\n",
    "    return x.max() - x.min()\n",
    "\n",
    "# More comprehensive descriptive statistics\n",
    "descriptive_stats = pd.DataFrame({\n",
    "    'Mean': df.mean(),\n",
    "    'Median': df.median(),\n",
    "    'Mode': df.mode().iloc[0],  # Returns the first mode\n",
    "    'Standard Deviation': df.std(),\n",
    "    'Variance': df.var(),\n",
    "    'Range': df.apply(data_range),\n",
    "    'Skewness': df.skew(),\n",
    "    'Kurtosis': df.kurt(),\n",
    "    'Q1': df.quantile(0.25),\n",
    "    'Q3': df.quantile(0.75),\n",
    "    'Interquartile Range (IQR)': df.quantile(0.75) - df.quantile(0.25),\n",
    "    'Min': df.min(),\n",
    "    'Max': df.max(),\n",
    "    'Count': df.count(),\n",
    "    'Missing': df.isna().sum(),\n",
    "})\n",
    "\n",
    "# Display the more detailed descriptive statistics\n",
    "print(descriptive_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58cb764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed descriptive statistics exported to detailed_descriptive_statistics.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create the dataset (replace with your data)\n",
    "data = {\n",
    "    'J1': [4, 2, 2, 4, 2, 4, 3, 1, 2, 4, 4, 3, 2, 2, 4, 2, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1, 4, 1, 2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 3, 2, 1, 5, 2, 1, 2, 2, 1, 4, 2, 1, 1, 4, 2, 2, 4, 1, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1, 4, 2, 1, 2, 1, 1, 2, 2, 1, 2, 2, 2, 2, 4, 2, 1, 1, 4, 2, 4, 2, 2, 1, 2, 2, 2],\n",
    "    'J2': [2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 1, 3, 2, 4, 2, 4, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 3, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 4, 2, 2, 4, 3, 2, 2, 4, 2, 1, 2, 4, 2, 4, 1, 1, 1, 2, 1, 1, 5, 5, 1, 2, 2, 1, 2, 1, 4, 2, 2, 4, 1, 1, 2, 2, 1, 2, 2, 4, 2, 4],\n",
    "    'J3': [1, 2, 3, 3, 3, 2, 2, 4, 3, 4, 3, 2, 3, 2, 1, 4, 3, 2, 2, 1, 4, 2, 3, 3, 4, 4, 3, 3, 4, 3, 5, 5, 2, 2, 4, 3, 2, 3, 2, 4, 2, 3, 4, 4, 4, 4, 4, 2, 4, 4, 3, 2, 3, 2, 4, 4, 4, 2, 4, 2, 3, 2, 4, 4, 3, 2, 3, 4, 4, 5, 5, 4, 5, 3, 2, 4, 3, 3, 3, 3, 3, 4, 2, 5, 4, 3, 4, 4, 4, 4, 2, 2, 4, 2, 1, 4, 4, 4, 4, 4],\n",
    "    'J4': [1, 1, 2, 2, 3, 2, 2, 2, 3, 4, 2, 2, 3, 2, 1, 4, 3, 5, 5, 1, 2, 3, 2, 3, 4, 2, 3, 3, 2, 3, 5, 5, 4, 2, 4, 3, 3, 3, 4, 2, 1, 3, 5, 4, 3, 5, 4, 2, 2, 4, 4, 2, 4, 4, 4, 2, 4, 2, 2, 4, 2, 2, 3, 4, 4, 2, 2, 2, 2, 4, 4, 4, 2, 1, 4, 1, 1, 4, 5, 2, 2, 4, 2, 5, 1, 5, 4, 5, 5, 5, 2, 3, 5, 2, 1, 2, 5, 2, 3, 2],\n",
    "    'J5': [1, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 1, 2, 2, 4, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 3, 4, 3, 1, 2, 1, 2, 1, 2, 2, 4, 2, 2, 3, 2, 1, 2, 2, 1, 2, 2, 4, 2, 2, 4, 2, 1, 2, 1, 2, 2, 2, 3, 2, 4, 3, 1, 2, 2, 2, 3, 3, 4, 2, 1, 4, 2, 1, 2, 4, 4, 1, 4, 4, 4, 4, 2, 4, 3, 2, 2, 1, 2, 1, 4, 3, 1, 3, 3, 2],\n",
    "    'J6': [2, 4, 5, 4, 1, 3, 4, 4, 5, None, 2, 4, 5, 2, 4, 3, 4, 2, 4, 4, 4, 4, 4, 4, 5, 5, 4, 5, 3, 4, 3, 1, 4, 4, 4, 5, 5, 5, 4, 4, 4, 4, 5, 4, 4, 4, 4, 2, 2, 4, 4, 3, 4, 2, 2, 4, 5, 5, 2, 5, 5, 2, 4, 5, 4, 4, 5, 5, 3, 4, 4, 4, 5, 4, 5, 5, 5, 5, 5, 4, 4, 5, 5, 5, 5, 4, 2, 4, 4, 4, 4, 2, 3, 5, 3, 4, 2, 5, 4, 3, 3],\n",
    "}\n",
    "\n",
    "# Find the maximum length of arrays\n",
    "max_length = max(len(lst) for lst in data.values())\n",
    "\n",
    "# Ensure all arrays are of the same length by padding with None\n",
    "for key, value in data.items():\n",
    "    if len(value) < max_length:\n",
    "        value.extend([None] * (max_length - len(value)))\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Function to calculate range\n",
    "def data_range(x):\n",
    "    return x.max() - x.min()\n",
    "\n",
    "# Function to calculate Interquartile Range (IQR)\n",
    "def iqr(x):\n",
    "    return x.quantile(0.75) - x.quantile(0.25)\n",
    "\n",
    "# Calculate detailed descriptive statistics\n",
    "descriptive_stats = pd.DataFrame({\n",
    "    'Mean': df.mean(),\n",
    "    'Median': df.median(),\n",
    "    'Mode': df.mode().iloc[0],  # Get the first mode in case of multiple\n",
    "    'Variance': df.var(),\n",
    "    'Standard Deviation': df.std(),\n",
    "    'Min': df.min(),\n",
    "    'Max': df.max(),\n",
    "    'Range': df.apply(data_range),\n",
    "    'Skewness': df.skew(),\n",
    "    'Kurtosis': df.kurtosis(),\n",
    "    'IQR': df.apply(iqr),\n",
    "    '25th Percentile (Q1)': df.quantile(0.25),\n",
    "    '50th Percentile (Q2)': df.quantile(0.50),\n",
    "    '75th Percentile (Q3)': df.quantile(0.75),\n",
    "    'Missing Values': df.isnull().sum()\n",
    "})\n",
    "\n",
    "# Export descriptive statistics to a CSV file\n",
    "csv_filename = 'detailed_descriptive_statistics.csv'\n",
    "descriptive_stats.to_csv(csv_filename)\n",
    "\n",
    "print(f\"Detailed descriptive statistics exported to {csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d84ec20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed Descriptive Statistics:\n",
      "\n",
      "    Mean  Median  Mode  Variance  Standard Deviation  Min  Max  Range  \\\n",
      "J1  2.01     2.0   2.0  1.020101            1.010001  1.0  5.0    4.0   \n",
      "J2  2.13     2.0   2.0  0.942525            0.970837  1.0  5.0    4.0   \n",
      "J3  3.17     3.0   4.0  1.011212            1.005590  1.0  5.0    4.0   \n",
      "J4  2.97     3.0   2.0  1.564747            1.250899  1.0  5.0    4.0   \n",
      "J5  2.27     2.0   2.0  0.906162            0.951925  1.0  4.0    3.0   \n",
      "J6  3.87     4.0   4.0  1.083939            1.041124  1.0  5.0    4.0   \n",
      "\n",
      "    Skewness  Kurtosis   IQR  25th Percentile (Q1)  50th Percentile (Q2)  \\\n",
      "J1  1.060127  0.379430  1.00                  1.00                   2.0   \n",
      "J2  1.288502  1.425520  0.00                  2.00                   2.0   \n",
      "J3 -0.228545 -0.774748  2.00                  2.00                   3.0   \n",
      "J4  0.184015 -1.136590  2.00                  2.00                   3.0   \n",
      "J5  0.649625 -0.446239  1.00                  2.00                   2.0   \n",
      "J6 -0.885292  0.082800  1.25                  3.75                   4.0   \n",
      "\n",
      "    75th Percentile (Q3)  Missing Values  \n",
      "J1                   2.0               1  \n",
      "J2                   2.0               1  \n",
      "J3                   4.0               1  \n",
      "J4                   4.0               1  \n",
      "J5                   3.0               1  \n",
      "J6                   5.0               1  \n",
      "\n",
      "Detailed descriptive statistics exported to C:\\Users\\padra\\Desktop\\detailed_descriptive_statistics.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Create the dataset (replace with your data)\n",
    "data = {\n",
    "    'J1': [4, 2, 2, 4, 2, 4, 3, 1, 2, 4, 4, 3, 2, 2, 4, 2, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1, 4, 1, 2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 3, 2, 1, 5, 2, 1, 2, 2, 1, 4, 2, 1, 1, 4, 2, 2, 4, 1, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1, 4, 2, 1, 2, 1, 1, 2, 2, 1, 2, 2, 2, 2, 4, 2, 1, 1, 4, 2, 4, 2, 2, 1, 2, 2, 2],\n",
    "    'J2': [2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 1, 3, 2, 4, 2, 4, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 3, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 4, 2, 2, 4, 3, 2, 2, 4, 2, 1, 2, 4, 2, 4, 1, 1, 1, 2, 1, 1, 5, 5, 1, 2, 2, 1, 2, 1, 4, 2, 2, 4, 1, 1, 2, 2, 1, 2, 2, 4, 2, 4],\n",
    "    'J3': [1, 2, 3, 3, 3, 2, 2, 4, 3, 4, 3, 2, 3, 2, 1, 4, 3, 2, 2, 1, 4, 2, 3, 3, 4, 4, 3, 3, 4, 3, 5, 5, 2, 2, 4, 3, 2, 3, 2, 4, 2, 3, 4, 4, 4, 4, 4, 2, 4, 4, 3, 2, 3, 2, 4, 4, 4, 2, 4, 2, 3, 2, 4, 4, 3, 2, 3, 4, 4, 5, 5, 4, 5, 3, 2, 4, 3, 3, 3, 3, 3, 4, 2, 5, 4, 3, 4, 4, 4, 4, 2, 2, 4, 2, 1, 4, 4, 4, 4, 4],\n",
    "    'J4': [1, 1, 2, 2, 3, 2, 2, 2, 3, 4, 2, 2, 3, 2, 1, 4, 3, 5, 5, 1, 2, 3, 2, 3, 4, 2, 3, 3, 2, 3, 5, 5, 4, 2, 4, 3, 3, 3, 4, 2, 1, 3, 5, 4, 3, 5, 4, 2, 2, 4, 4, 2, 4, 4, 4, 2, 4, 2, 2, 4, 2, 2, 3, 4, 4, 2, 2, 2, 2, 4, 4, 4, 2, 1, 4, 1, 1, 4, 5, 2, 2, 4, 2, 5, 1, 5, 4, 5, 5, 5, 2, 3, 5, 2, 1, 2, 5, 2, 3, 2],\n",
    "    'J5': [1, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 1, 2, 2, 4, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 3, 4, 3, 1, 2, 1, 2, 1, 2, 2, 4, 2, 2, 3, 2, 1, 2, 2, 1, 2, 2, 4, 2, 2, 4, 2, 1, 2, 1, 2, 2, 2, 3, 2, 4, 3, 1, 2, 2, 2, 3, 3, 4, 2, 1, 4, 2, 1, 2, 4, 4, 1, 4, 4, 4, 4, 2, 4, 3, 2, 2, 1, 2, 1, 4, 3, 1, 3, 3, 2],\n",
    "    'J6': [2, 4, 5, 4, 1, 3, 4, 4, 5, None, 2, 4, 5, 2, 4, 3, 4, 2, 4, 4, 4, 4, 4, 4, 5, 5, 4, 5, 3, 4, 3, 1, 4, 4, 4, 5, 5, 5, 4, 4, 4, 4, 5, 4, 4, 4, 4, 2, 2, 4, 4, 3, 4, 2, 2, 4, 5, 5, 2, 5, 5, 2, 4, 5, 4, 4, 5, 5, 3, 4, 4, 4, 5, 4, 5, 5, 5, 5, 5, 4, 4, 5, 5, 5, 5, 4, 2, 4, 4, 4, 4, 2, 3, 5, 3, 4, 2, 5, 4, 3, 3],\n",
    "}\n",
    "\n",
    "# Find the maximum length of arrays\n",
    "max_length = max(len(lst) for lst in data.values())\n",
    "\n",
    "# Ensure all arrays are of the same length by padding with None\n",
    "for key, value in data.items():\n",
    "    if len(value) < max_length:\n",
    "        value.extend([None] * (max_length - len(value)))\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define custom range function\n",
    "def data_range(x):\n",
    "    return x.max() - x.min()\n",
    "\n",
    "# Define custom interquartile range (IQR) function\n",
    "def iqr(x):\n",
    "    return x.quantile(0.75) - x.quantile(0.25)\n",
    "\n",
    "# Calculate detailed descriptive statistics\n",
    "descriptive_stats = pd.DataFrame({\n",
    "    'Mean': df.mean(),\n",
    "    'Median': df.median(),\n",
    "    'Mode': df.mode().iloc[0],  # Get the first mode in case of multiple\n",
    "    'Variance': df.var(),\n",
    "    'Standard Deviation': df.std(),\n",
    "    'Min': df.min(),\n",
    "    'Max': df.max(),\n",
    "    'Range': df.apply(data_range),\n",
    "    'Skewness': df.skew(),\n",
    "    'Kurtosis': df.kurtosis(),\n",
    "    'IQR': df.apply(iqr),\n",
    "    '25th Percentile (Q1)': df.quantile(0.25),\n",
    "    '50th Percentile (Q2)': df.quantile(0.50),\n",
    "    '75th Percentile (Q3)': df.quantile(0.75),\n",
    "    'Missing Values': df.isnull().sum()\n",
    "})\n",
    "\n",
    "# Display the detailed statistics in Python environment\n",
    "print(\"Detailed Descriptive Statistics:\\n\")\n",
    "print(descriptive_stats)\n",
    "\n",
    "# Get desktop path and export the CSV file\n",
    "desktop_path = os.path.join(os.path.expanduser(\"~\"), \"Desktop\")\n",
    "csv_filename = os.path.join(desktop_path, 'detailed_descriptive_statistics.csv')\n",
    "\n",
    "# Export to CSV\n",
    "descriptive_stats.to_csv(csv_filename)\n",
    "\n",
    "print(f\"\\nDetailed descriptive statistics exported to {csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0530b82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed Descriptive Statistics:\n",
      "\n",
      "    Mean  Median  Mode  Variance  Standard Deviation  Min  Max  Range  \\\n",
      "J1  2.01     2.0   2.0  1.020101            1.010001  1.0  5.0    4.0   \n",
      "J2  2.13     2.0   2.0  0.942525            0.970837  1.0  5.0    4.0   \n",
      "J3  3.17     3.0   4.0  1.011212            1.005590  1.0  5.0    4.0   \n",
      "J4  2.97     3.0   2.0  1.564747            1.250899  1.0  5.0    4.0   \n",
      "J5  2.27     2.0   2.0  0.906162            0.951925  1.0  4.0    3.0   \n",
      "J6  3.87     4.0   4.0  1.083939            1.041124  1.0  5.0    4.0   \n",
      "\n",
      "    Skewness  Kurtosis   IQR  25th Percentile (Q1)  50th Percentile (Q2)  \\\n",
      "J1  1.060127  0.379430  1.00                  1.00                   2.0   \n",
      "J2  1.288502  1.425520  0.00                  2.00                   2.0   \n",
      "J3 -0.228545 -0.774748  2.00                  2.00                   3.0   \n",
      "J4  0.184015 -1.136590  2.00                  2.00                   3.0   \n",
      "J5  0.649625 -0.446239  1.00                  2.00                   2.0   \n",
      "J6 -0.885292  0.082800  1.25                  3.75                   4.0   \n",
      "\n",
      "    75th Percentile (Q3)  Missing Values  \n",
      "J1                   2.0               1  \n",
      "J2                   2.0               1  \n",
      "J3                   4.0               1  \n",
      "J4                   4.0               1  \n",
      "J5                   3.0               1  \n",
      "J6                   5.0               1  \n",
      "\n",
      "Detailed descriptive statistics exported to C:\\Users\\padra\\Desktop\\Descriptive Statistics of J1toJ6.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Create the dataset (replace with your data)\n",
    "data = {\n",
    "    'J1': [4, 2, 2, 4, 2, 4, 3, 1, 2, 4, 4, 3, 2, 2, 4, 2, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1, 4, 1, 2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 3, 2, 1, 5, 2, 1, 2, 2, 1, 4, 2, 1, 1, 4, 2, 2, 4, 1, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1, 4, 2, 1, 2, 1, 1, 2, 2, 1, 2, 2, 2, 2, 4, 2, 1, 1, 4, 2, 4, 2, 2, 1, 2, 2, 2],\n",
    "    'J2': [2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 1, 3, 2, 4, 2, 4, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 3, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 4, 2, 2, 4, 3, 2, 2, 4, 2, 1, 2, 4, 2, 4, 1, 1, 1, 2, 1, 1, 5, 5, 1, 2, 2, 1, 2, 1, 4, 2, 2, 4, 1, 1, 2, 2, 1, 2, 2, 4, 2, 4],\n",
    "    'J3': [1, 2, 3, 3, 3, 2, 2, 4, 3, 4, 3, 2, 3, 2, 1, 4, 3, 2, 2, 1, 4, 2, 3, 3, 4, 4, 3, 3, 4, 3, 5, 5, 2, 2, 4, 3, 2, 3, 2, 4, 2, 3, 4, 4, 4, 4, 4, 2, 4, 4, 3, 2, 3, 2, 4, 4, 4, 2, 4, 2, 3, 2, 4, 4, 3, 2, 3, 4, 4, 5, 5, 4, 5, 3, 2, 4, 3, 3, 3, 3, 3, 4, 2, 5, 4, 3, 4, 4, 4, 4, 2, 2, 4, 2, 1, 4, 4, 4, 4, 4],\n",
    "    'J4': [1, 1, 2, 2, 3, 2, 2, 2, 3, 4, 2, 2, 3, 2, 1, 4, 3, 5, 5, 1, 2, 3, 2, 3, 4, 2, 3, 3, 2, 3, 5, 5, 4, 2, 4, 3, 3, 3, 4, 2, 1, 3, 5, 4, 3, 5, 4, 2, 2, 4, 4, 2, 4, 4, 4, 2, 4, 2, 2, 4, 2, 2, 3, 4, 4, 2, 2, 2, 2, 4, 4, 4, 2, 1, 4, 1, 1, 4, 5, 2, 2, 4, 2, 5, 1, 5, 4, 5, 5, 5, 2, 3, 5, 2, 1, 2, 5, 2, 3, 2],\n",
    "    'J5': [1, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 1, 2, 2, 4, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 3, 4, 3, 1, 2, 1, 2, 1, 2, 2, 4, 2, 2, 3, 2, 1, 2, 2, 1, 2, 2, 4, 2, 2, 4, 2, 1, 2, 1, 2, 2, 2, 3, 2, 4, 3, 1, 2, 2, 2, 3, 3, 4, 2, 1, 4, 2, 1, 2, 4, 4, 1, 4, 4, 4, 4, 2, 4, 3, 2, 2, 1, 2, 1, 4, 3, 1, 3, 3, 2],\n",
    "    'J6': [2, 4, 5, 4, 1, 3, 4, 4, 5, None, 2, 4, 5, 2, 4, 3, 4, 2, 4, 4, 4, 4, 4, 4, 5, 5, 4, 5, 3, 4, 3, 1, 4, 4, 4, 5, 5, 5, 4, 4, 4, 4, 5, 4, 4, 4, 4, 2, 2, 4, 4, 3, 4, 2, 2, 4, 5, 5, 2, 5, 5, 2, 4, 5, 4, 4, 5, 5, 3, 4, 4, 4, 5, 4, 5, 5, 5, 5, 5, 4, 4, 5, 5, 5, 5, 4, 2, 4, 4, 4, 4, 2, 3, 5, 3, 4, 2, 5, 4, 3, 3],\n",
    "}\n",
    "\n",
    "# Find the maximum length of arrays\n",
    "max_length = max(len(lst) for lst in data.values())\n",
    "\n",
    "# Ensure all arrays are of the same length by padding with None\n",
    "for key, value in data.items():\n",
    "    if len(value) < max_length:\n",
    "        value.extend([None] * (max_length - len(value)))\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define custom range function\n",
    "def data_range(x):\n",
    "    return x.max() - x.min()\n",
    "\n",
    "# Define custom interquartile range (IQR) function\n",
    "def iqr(x):\n",
    "    return x.quantile(0.75) - x.quantile(0.25)\n",
    "\n",
    "# Calculate detailed descriptive statistics\n",
    "descriptive_stats = pd.DataFrame({\n",
    "    'Mean': df.mean(),\n",
    "    'Median': df.median(),\n",
    "    'Mode': df.mode().iloc[0],  # Get the first mode in case of multiple\n",
    "    'Variance': df.var(),\n",
    "    'Standard Deviation': df.std(),\n",
    "    'Min': df.min(),\n",
    "    'Max': df.max(),\n",
    "    'Range': df.apply(data_range),\n",
    "    'Skewness': df.skew(),\n",
    "    'Kurtosis': df.kurtosis(),\n",
    "    'IQR': df.apply(iqr),\n",
    "    '25th Percentile (Q1)': df.quantile(0.25),\n",
    "    '50th Percentile (Q2)': df.quantile(0.50),\n",
    "    '75th Percentile (Q3)': df.quantile(0.75),\n",
    "    'Missing Values': df.isnull().sum()\n",
    "})\n",
    "\n",
    "# Display the detailed statistics in Python environment\n",
    "print(\"Detailed Descriptive Statistics:\\n\")\n",
    "print(descriptive_stats)\n",
    "\n",
    "# Get desktop path and export the CSV file with the specified name\n",
    "desktop_path = os.path.join(os.path.expanduser(\"~\"), \"Desktop\")\n",
    "csv_filename = os.path.join(desktop_path, 'Descriptive Statistics of J1toJ6.csv')\n",
    "\n",
    "# Export to CSV\n",
    "descriptive_stats.to_csv(csv_filename)\n",
    "\n",
    "print(f\"\\nDetailed descriptive statistics exported to {csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9479ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive statistics exported to C:/path/to/your/directory\\detailed_descriptive_statistics.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Create the dataset\n",
    "data = {\n",
    "    'K1': [2, 4, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 4, 4, 1, 1, 2, 2, 2, 2, 4, 5, 1, 2, 2, 2, 4, 2, 4, 2, 4, 2, 4, 2, 2, 2, 2, 1, 2, 1, 2, 4, 2, 2, 2, 2, 2, 4, 5, 4, 4, 4, 4, 4, 4, 4, 5, 4, 5, 4, 4, 4, 4, 4, 5, 5, 5, 5, 2, 4, 4, 2, 2, 4, 4, 4, 4, 2, 2, 4, 4, 4, 4, 4, 4, 2, 2, 5, 5, 5, 5],\n",
    "    'K2': [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4],\n",
    "    'K3': [2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
    "    'K4': [4, 5, 2, 4, 4, 4, 4, 3, 2, 4, 2, 3, 2, 4, 3, 4, 4, 3, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4],\n",
    "    'K5': [4, 5, 2, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4],\n",
    "    'K6': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
    "    'K7': [4, 2, 2, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4],\n",
    "    'K8': [4, 2, 2, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4],\n",
    "    'K9': [4, 5, 5, 4, 4, 4, 4, 5, 5, 5, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],\n",
    "    'K10': [2, 5, 5, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4],\n",
    "    'K11': [4, 5, 5, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4],\n",
    "}\n",
    "\n",
    "# Find the maximum length of arrays\n",
    "max_length = max(len(lst) for lst in data.values())\n",
    "\n",
    "# Ensure all arrays are of the same length by padding with None\n",
    "for key, value in data.items():\n",
    "    if len(value) < max_length:\n",
    "        value.extend([None] * (max_length - len(value)))\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define custom range function\n",
    "def data_range(x):\n",
    "    return x.max() - x.min()\n",
    "\n",
    "# Define custom interquartile range (IQR) function\n",
    "def iqr(x):\n",
    "    return x.quantile(0.75) - x.quantile(0.25)\n",
    "\n",
    "# Calculate detailed descriptive statistics\n",
    "descriptive_stats = pd.DataFrame({\n",
    "    'Mean': df.mean(),\n",
    "    'Median': df.median(),\n",
    "    'Mode': df.mode().iloc[0],  # Get the first mode in case of multiple\n",
    "    'Variance': df.var(),\n",
    "    'Standard Deviation': df.std(),\n",
    "    'Min': df.min(),\n",
    "    'Max': df.max(),\n",
    "    'Range': df.apply(data_range),\n",
    "    'Skewness': df.skew(),\n",
    "    'Kurtosis': df.kurtosis(),\n",
    "    'IQR': df.apply(iqr),\n",
    "    '25th Percentile (Q1)': df.quantile(0.25),\n",
    "    '50th Percentile (Q2)': df.quantile(0.50),\n",
    "    '75th Percentile (Q3)': df.quantile(0.75),\n",
    "    'Missing Values': df.isnull().sum()\n",
    "})\n",
    "\n",
    "# Specify the output directory\n",
    "output_directory = \"C:/path/to/your/directory\"  # Change to your desired directory\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Export the descriptive statistics to a CSV file\n",
    "output_file_path = os.path.join(output_directory, \"detailed_descriptive_statistics.csv\")\n",
    "descriptive_stats.to_csv(output_file_path)\n",
    "\n",
    "print(f\"Descriptive statistics exported to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a0d909e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Mean  Median  Mode  Variance  Standard Deviation  Min  Max  Range  \\\n",
      "K1   3.031250     2.0   2.0  1.609539            1.268676  1.0  5.0    4.0   \n",
      "K2   3.920455     4.0   4.0  0.189002            0.434744  1.0  4.0    3.0   \n",
      "K3   2.000000     2.0   2.0  0.023529            0.153393  1.0  3.0    2.0   \n",
      "K4   3.847059     4.0   4.0  0.273950            0.523402  2.0  5.0    3.0   \n",
      "K5   3.976190     4.0   4.0  0.071715            0.267797  2.0  5.0    3.0   \n",
      "K6   2.000000     2.0   2.0  0.000000            0.000000  2.0  2.0    0.0   \n",
      "K7   3.941176     4.0   4.0  0.103641            0.321934  2.0  4.0    2.0   \n",
      "K8   3.939759     4.0   4.0  0.106083            0.325704  2.0  4.0    2.0   \n",
      "K9   4.904762     5.0   5.0  0.087206            0.295307  4.0  5.0    1.0   \n",
      "K10  3.987805     4.0   4.0  0.086269            0.293716  2.0  5.0    3.0   \n",
      "K11  4.012048     4.0   4.0  0.036438            0.190889  3.0  5.0    2.0   \n",
      "\n",
      "     Skewness   Kurtosis  IQR  25th Percentile (Q1)  50th Percentile (Q2)  \\\n",
      "K1   0.098249  -1.462056  2.0                   2.0                   2.0   \n",
      "K2  -5.587059  31.352395  0.0                   4.0                   4.0   \n",
      "K3   0.000000  42.500000  0.0                   2.0                   2.0   \n",
      "K4  -2.732554   7.463805  0.0                   4.0                   4.0   \n",
      "K5  -4.867167  40.349175  0.0                   4.0                   4.0   \n",
      "K6   0.000000   0.000000  0.0                   2.0                   2.0   \n",
      "K7  -5.644008  31.629093  0.0                   4.0                   4.0   \n",
      "K8  -5.573242  30.811718  0.0                   4.0                   4.0   \n",
      "K9  -2.808161   6.028776  0.0                   5.0                   5.0   \n",
      "K10 -3.368105  30.228332  0.0                   4.0                   4.0   \n",
      "K11  1.602266  26.082847  0.0                   4.0                   4.0   \n",
      "\n",
      "     75th Percentile (Q3)  Missing Values  \n",
      "K1                    4.0               0  \n",
      "K2                    4.0               8  \n",
      "K3                    2.0              10  \n",
      "K4                    4.0              11  \n",
      "K5                    4.0              12  \n",
      "K6                    2.0              10  \n",
      "K7                    4.0              11  \n",
      "K8                    4.0              13  \n",
      "K9                    5.0              12  \n",
      "K10                   4.0              14  \n",
      "K11                   4.0              13  \n",
      "Descriptive statistics exported to: C:\\Users\\padra\\Desktop\\Descriptive Statistics of K1 to K11.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Create the dataset\n",
    "data = {\n",
    "    'K1': [2, 4, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 4, 4, 1, 1, 2, 2, 2, 2, 4, 5, 1, 2, 2, 2, 4, 2, 4, 2, 4, 2, 4, 2, 2, 2, 2, 1, 2, 1, 2, 4, 2, 2, 2, 2, 2, 4, 5, 4, 4, 4, 4, 4, 4, 4, 5, 4, 5, 4, 4, 4, 4, 4, 5, 5, 5, 5, 2, 4, 4, 2, 2, 4, 4, 4, 4, 2, 2, 4, 4, 4, 4, 4, 4, 2, 2, 5, 5, 5, 5],\n",
    "    'K2': [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4],\n",
    "    'K3': [2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
    "    'K4': [4, 5, 2, 4, 4, 4, 4, 3, 2, 4, 2, 3, 2, 4, 3, 4, 4, 3, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4],\n",
    "    'K5': [4, 5, 2, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4],\n",
    "    'K6': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
    "    'K7': [4, 2, 2, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4],\n",
    "    'K8': [4, 2, 2, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4],\n",
    "    'K9': [4, 5, 5, 4, 4, 4, 4, 5, 5, 5, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],\n",
    "    'K10': [2, 5, 5, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4],\n",
    "    'K11': [4, 5, 5, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4],\n",
    "}\n",
    "\n",
    "# Find the maximum length of arrays\n",
    "max_length = max(len(lst) for lst in data.values())\n",
    "\n",
    "# Ensure all arrays are of the same length by padding with None\n",
    "for key, value in data.items():\n",
    "    if len(value) < max_length:\n",
    "        value.extend([None] * (max_length - len(value)))\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define custom range function\n",
    "def data_range(x):\n",
    "    return x.max() - x.min()\n",
    "\n",
    "# Define custom interquartile range (IQR) function\n",
    "def iqr(x):\n",
    "    return x.quantile(0.75) - x.quantile(0.25)\n",
    "\n",
    "# Calculate detailed descriptive statistics\n",
    "descriptive_stats = pd.DataFrame({\n",
    "    'Mean': df.mean(),\n",
    "    'Median': df.median(),\n",
    "    'Mode': df.mode().iloc[0],  # Get the first mode in case of multiple\n",
    "    'Variance': df.var(),\n",
    "    'Standard Deviation': df.std(),\n",
    "    'Min': df.min(),\n",
    "    'Max': df.max(),\n",
    "    'Range': df.apply(data_range),\n",
    "    'Skewness': df.skew(),\n",
    "    'Kurtosis': df.kurtosis(),\n",
    "    'IQR': df.apply(iqr),\n",
    "    '25th Percentile (Q1)': df.quantile(0.25),\n",
    "    '50th Percentile (Q2)': df.quantile(0.50),\n",
    "    '75th Percentile (Q3)': df.quantile(0.75),\n",
    "    'Missing Values': df.isnull().sum()\n",
    "})\n",
    "\n",
    "# Display the results in the Python IDE\n",
    "print(descriptive_stats)\n",
    "\n",
    "# Define the path for exporting the file to the desktop\n",
    "desktop_path = os.path.join(os.path.expanduser(\"~\"), \"Desktop\", \"Descriptive Statistics of K1 to K11.csv\")\n",
    "\n",
    "# Export the DataFrame to a CSV file\n",
    "descriptive_stats.to_csv(desktop_path)\n",
    "\n",
    "print(f\"Descriptive statistics exported to: {desktop_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1d1d1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\padra\\AppData\\Local\\Temp/ipykernel_27576/2115373078.py:28: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  'Mean': df.mean(),\n",
      "C:\\Users\\padra\\AppData\\Local\\Temp/ipykernel_27576/2115373078.py:29: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  'Median': df.median(),\n",
      "C:\\Users\\padra\\AppData\\Local\\Temp/ipykernel_27576/2115373078.py:31: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  'Variance': df.var(),\n",
      "C:\\Users\\padra\\AppData\\Local\\Temp/ipykernel_27576/2115373078.py:32: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  'Standard Deviation': df.std(),\n",
      "C:\\Users\\padra\\AppData\\Local\\Temp/ipykernel_27576/2115373078.py:33: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  'Min': df.min(),\n",
      "C:\\Users\\padra\\AppData\\Local\\Temp/ipykernel_27576/2115373078.py:34: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  'Max': df.max(),\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'>=' not supported between instances of 'str' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_27576/2115373078.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;34m'Min'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;34m'Max'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[1;34m'Range'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_range\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m     \u001b[1;34m'Skewness'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mskew\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;34m'Kurtosis'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkurtosis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   8738\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8739\u001b[0m         )\n\u001b[1;32m-> 8740\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   8741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8742\u001b[0m     def applymap(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    686\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    811\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 812\u001b[1;33m         \u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    814\u001b[0m         \u001b[1;31m# wrap results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    826\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m                 \u001b[1;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m                 \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m                     \u001b[1;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_27576/2115373078.py\u001b[0m in \u001b[0;36mdata_range\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m# Define custom range function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdata_range\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m# Define custom interquartile range (IQR) function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mmax\u001b[1;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  10817\u001b[0m         )\n\u001b[0;32m  10818\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 10819\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m  10820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10821\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"max\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mmax\u001b[1;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  10362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10363\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 10364\u001b[1;33m         return self._stat_function(\n\u001b[0m\u001b[0;32m  10365\u001b[0m             \u001b[1;34m\"max\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnanops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnanmax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10366\u001b[0m         )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_stat_function\u001b[1;34m(self, name, func, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  10352\u001b[0m                 \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10353\u001b[0m             )\n\u001b[1;32m> 10354\u001b[1;33m         return self._reduce(\n\u001b[0m\u001b[0;32m  10355\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10356\u001b[0m         )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m   4390\u001b[0m                 )\n\u001b[0;32m   4391\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4392\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4394\u001b[0m     def _reindex_indexer(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36mf\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    153\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[0;32m    408\u001b[0m             \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 410\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdatetimelike\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36mreduction\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m   1015\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1017\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1018\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1019\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_maybe_null_out\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_amax\u001b[1;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m     37\u001b[0m def _amax(a, axis=None, out=None, keepdims=False,\n\u001b[0;32m     38\u001b[0m           initial=_NoValue, where=True):\n\u001b[1;32m---> 39\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mumr_maximum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m def _amin(a, axis=None, out=None, keepdims=False,\n",
      "\u001b[1;31mTypeError\u001b[0m: '>=' not supported between instances of 'str' and 'float'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the path for the input CSV file\n",
    "input_file_path = r\"C:\\Users\\padra\\Desktop\\Book1.csv\"\n",
    "\n",
    "# Read the dataset from the CSV file\n",
    "df = pd.read_csv(input_file_path)\n",
    "\n",
    "# Check for missing values and pad the DataFrame if necessary\n",
    "max_length = len(df)\n",
    "\n",
    "# Ensure all columns have the same length by padding with None if necessary\n",
    "for column in df.columns:\n",
    "    if len(df[column]) < max_length:\n",
    "        df[column] = df[column].tolist() + [None] * (max_length - len(df[column]))\n",
    "\n",
    "# Define custom range function\n",
    "def data_range(x):\n",
    "    return x.max() - x.min()\n",
    "\n",
    "# Define custom interquartile range (IQR) function\n",
    "def iqr(x):\n",
    "    return x.quantile(0.75) - x.quantile(0.25)\n",
    "\n",
    "# Calculate detailed descriptive statistics\n",
    "descriptive_stats = pd.DataFrame({\n",
    "    'Mean': df.mean(),\n",
    "    'Median': df.median(),\n",
    "    'Mode': df.mode().iloc[0],  # Get the first mode in case of multiple\n",
    "    'Variance': df.var(),\n",
    "    'Standard Deviation': df.std(),\n",
    "    'Min': df.min(),\n",
    "    'Max': df.max(),\n",
    "    'Range': df.apply(data_range),\n",
    "    'Skewness': df.skew(),\n",
    "    'Kurtosis': df.kurtosis(),\n",
    "    'IQR': df.apply(iqr),\n",
    "    '25th Percentile (Q1)': df.quantile(0.25),\n",
    "    '50th Percentile (Q2)': df.quantile(0.50),\n",
    "    '75th Percentile (Q3)': df.quantile(0.75),\n",
    "    'Missing Values': df.isnull().sum()\n",
    "})\n",
    "\n",
    "# Display the results in the Python IDE\n",
    "print(descriptive_stats)\n",
    "\n",
    "# Define the path for exporting the file to the desktop\n",
    "desktop_path = r\"C:\\Users\\padra\\Desktop\\Descriptive Statistics of Book1.csv\"\n",
    "\n",
    "# Export the DataFrame to a CSV file\n",
    "descriptive_stats.to_csv(desktop_path)\n",
    "\n",
    "print(f\"Descriptive statistics exported to: {desktop_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "450bf88b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Mean  Median  Mode  Variance  Standard Deviation  Min   Max  Range  \\\n",
      "L1   2.989011     3.0   4.0  1.640848            1.280956  0.0   5.0    5.0   \n",
      "L2   3.254945     4.0   4.0  1.516358            1.231405  0.0   5.0    5.0   \n",
      "L3   3.432967     4.0   4.0  1.558823            1.248528  0.0   5.0    5.0   \n",
      "L4   2.980220     3.0   4.0  2.565687            1.601776  0.0  24.0   24.0   \n",
      "L5   3.485714     4.0   4.0  1.457395            1.207226  0.0   5.0    5.0   \n",
      "L6   3.593407     4.0   4.0  1.303481            1.141701  0.0   5.0    5.0   \n",
      "L7   3.131868     4.0   4.0  1.660987            1.288793  0.0   5.0    5.0   \n",
      "L8   3.292308     4.0   4.0  1.542121            1.241822  0.0   5.0    5.0   \n",
      "L9   3.696703     4.0   4.0  1.462875            1.209494  0.0   5.0    5.0   \n",
      "L10  3.301099     4.0   4.0  1.554514            1.246802  0.0   5.0    5.0   \n",
      "L11  3.619780     4.0   4.0  1.368330            1.169757  0.0   5.0    5.0   \n",
      "L12  3.718681     4.0   4.0  1.414078            1.189150  0.0   5.0    5.0   \n",
      "L13  3.498901     4.0   4.0  1.691078            1.300415  0.0   5.0    5.0   \n",
      "L14  3.426374     4.0   4.0  1.795779            1.340067  0.0   5.0    5.0   \n",
      "L15  3.019780     3.0   4.0  1.785951            1.336395  0.0   5.0    5.0   \n",
      "L16  3.960440     4.0   4.0  1.355260            1.164156  0.0   5.0    5.0   \n",
      "L17  3.549451     4.0   4.0  1.992593            1.411592  0.0   5.0    5.0   \n",
      "L18  2.789011     2.0   2.0  1.682258            1.297019  0.0   5.0    5.0   \n",
      "L19  3.246154     4.0   4.0  1.661742            1.289086  0.0   5.0    5.0   \n",
      "L20  2.652747     2.0   2.0  1.425405            1.193903  0.0   5.0    5.0   \n",
      "L21  3.360440     4.0   4.0  1.565832            1.251332  0.0   5.0    5.0   \n",
      "L22  3.076923     3.0   4.0  1.674687            1.294097  0.0   5.0    5.0   \n",
      "\n",
      "     Skewness   Kurtosis  IQR  25th Percentile (Q1)  50th Percentile (Q2)  \\\n",
      "L1  -0.282555  -0.880596  2.0                   2.0                   3.0   \n",
      "L2  -0.708612  -0.199581  2.0                   2.0                   4.0   \n",
      "L3  -0.678828  -0.489184  2.0                   2.0                   4.0   \n",
      "L4   4.825693  64.016107  2.0                   2.0                   3.0   \n",
      "L5  -1.000010   0.342899  1.0                   3.0                   4.0   \n",
      "L6  -1.109874   0.628515  1.0                   3.0                   4.0   \n",
      "L7  -0.470616  -0.641954  2.0                   2.0                   4.0   \n",
      "L8  -0.755907  -0.157607  2.0                   2.0                   4.0   \n",
      "L9  -1.404200   1.528619  0.0                   4.0                   4.0   \n",
      "L10 -0.571788  -0.667769  2.0                   2.0                   4.0   \n",
      "L11 -1.315007   1.371298  1.0                   3.0                   4.0   \n",
      "L12 -1.518361   2.038274  0.0                   4.0                   4.0   \n",
      "L13 -0.942244   0.035861  2.0                   2.0                   4.0   \n",
      "L14 -0.972771   0.110015  2.0                   2.0                   4.0   \n",
      "L15 -0.353275  -0.912796  2.0                   2.0                   3.0   \n",
      "L16 -1.756940   3.080193  1.0                   4.0                   4.0   \n",
      "L17 -1.191344   0.509632  1.0                   3.0                   4.0   \n",
      "L18  0.062560  -0.979484  2.0                   2.0                   2.0   \n",
      "L19 -0.739379  -0.334087  2.0                   2.0                   4.0   \n",
      "L20  0.102974  -0.698538  2.0                   2.0                   2.0   \n",
      "L21 -0.801677   0.045876  2.0                   2.0                   4.0   \n",
      "L22 -0.351845  -0.802730  2.0                   2.0                   3.0   \n",
      "\n",
      "     75th Percentile (Q3)  Missing Values  \n",
      "L1                    4.0               2  \n",
      "L2                    4.0               2  \n",
      "L3                    4.0               2  \n",
      "L4                    4.0               2  \n",
      "L5                    4.0               2  \n",
      "L6                    4.0               2  \n",
      "L7                    4.0               2  \n",
      "L8                    4.0               2  \n",
      "L9                    4.0               2  \n",
      "L10                   4.0               2  \n",
      "L11                   4.0               2  \n",
      "L12                   4.0               2  \n",
      "L13                   4.0               2  \n",
      "L14                   4.0               2  \n",
      "L15                   4.0               2  \n",
      "L16                   5.0               2  \n",
      "L17                   4.0               2  \n",
      "L18                   4.0               2  \n",
      "L19                   4.0               2  \n",
      "L20                   4.0               2  \n",
      "L21                   4.0               2  \n",
      "L22                   4.0               2  \n",
      "Descriptive statistics exported to: C:\\Users\\padra\\Desktop\\Descriptive Statistics of Book1.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the path for the input CSV file\n",
    "input_file_path = r\"C:\\Users\\padra\\Desktop\\Book1.csv\"\n",
    "\n",
    "# Read the dataset from the CSV file\n",
    "df = pd.read_csv(input_file_path)\n",
    "\n",
    "# Convert all columns to numeric, forcing errors to NaN (useful if there are strings in the data)\n",
    "df = df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Check for missing values and pad the DataFrame if necessary\n",
    "max_length = len(df)\n",
    "\n",
    "# Ensure all columns have the same length by padding with None if necessary\n",
    "for column in df.columns:\n",
    "    if len(df[column]) < max_length:\n",
    "        df[column] = df[column].tolist() + [None] * (max_length - len(df[column]))\n",
    "\n",
    "# Define custom range function\n",
    "def data_range(x):\n",
    "    return x.max() - x.min()\n",
    "\n",
    "# Define custom interquartile range (IQR) function\n",
    "def iqr(x):\n",
    "    return x.quantile(0.75) - x.quantile(0.25)\n",
    "\n",
    "# Filter numeric columns only for descriptive statistics\n",
    "numeric_df = df.select_dtypes(include='number')\n",
    "\n",
    "# Calculate detailed descriptive statistics\n",
    "descriptive_stats = pd.DataFrame({\n",
    "    'Mean': numeric_df.mean(),\n",
    "    'Median': numeric_df.median(),\n",
    "    'Mode': numeric_df.mode().iloc[0],  # Get the first mode in case of multiple\n",
    "    'Variance': numeric_df.var(),\n",
    "    'Standard Deviation': numeric_df.std(),\n",
    "    'Min': numeric_df.min(),\n",
    "    'Max': numeric_df.max(),\n",
    "    'Range': numeric_df.apply(data_range),\n",
    "    'Skewness': numeric_df.skew(),\n",
    "    'Kurtosis': numeric_df.kurtosis(),\n",
    "    'IQR': numeric_df.apply(iqr),\n",
    "    '25th Percentile (Q1)': numeric_df.quantile(0.25),\n",
    "    '50th Percentile (Q2)': numeric_df.quantile(0.50),\n",
    "    '75th Percentile (Q3)': numeric_df.quantile(0.75),\n",
    "    'Missing Values': numeric_df.isnull().sum()\n",
    "})\n",
    "\n",
    "# Display the results in the Python IDE\n",
    "print(descriptive_stats)\n",
    "\n",
    "# Define the path for exporting the file to the desktop\n",
    "desktop_path = r\"C:\\Users\\padra\\Desktop\\Descriptive Statistics of Book1.csv\"\n",
    "\n",
    "# Export the DataFrame to a CSV file\n",
    "descriptive_stats.to_csv(desktop_path)\n",
    "\n",
    "print(f\"Descriptive statistics exported to: {desktop_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f0a4f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
